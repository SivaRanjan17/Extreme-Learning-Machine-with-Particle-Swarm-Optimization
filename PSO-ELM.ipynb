{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05ea2a468c9521de119e6af1f07ff928e1bade94b0f6948efedbcf9d9f0f8ee96",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from numpy import argmax, array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.linalg import pinv2\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "import math\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_ITRERATION = 10\n",
    "global input_weights\n",
    "global bias\n",
    "global g_best\n",
    "global p_best\n",
    "global g_best_x\n",
    "global p_best_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(22544, 42) (125973, 42)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"kdd_train.csv\")\n",
    "test = pd.read_csv(\"kdd_test.csv\")\n",
    "\n",
    "print(test.shape,train.shape)\n",
    "#print(test['duration'])"
   ]
  },
  {
   "source": [
    "# Data Pre-Process\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['protocol_type', 'service', \"flag\", \"labels\"]:\n",
    "    values_train = array(train[i])\n",
    "    values_test = array(test[i])\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded_train = label_encoder.fit_transform(values_train)\n",
    "    integer_encoded_test = label_encoder.fit_transform(values_test)\n",
    "    train[i] = integer_encoded_train\n",
    "    test[i] = integer_encoded_test\n",
    "\n",
    "X_train = train.iloc[:, :41]\n",
    "y_train = train.iloc[:, 41]\n",
    "\n",
    "X_test = test.iloc[:, :41]\n",
    "y_test = test.iloc[:, 41]\n",
    "\n",
    "#print(X_train.head(),y_train.head())\n",
    "#print(X_test.head(),y_test.head())\n",
    "#print(list(y_train))#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Column: 0, Selected True, Rank: 1.000\n",
      "Column: 1, Selected True, Rank: 1.000\n",
      "Column: 2, Selected True, Rank: 1.000\n",
      "Column: 3, Selected True, Rank: 1.000\n",
      "Column: 4, Selected True, Rank: 1.000\n",
      "Column: 5, Selected True, Rank: 1.000\n",
      "Column: 6, Selected False, Rank: 4.000\n",
      "Column: 7, Selected False, Rank: 11.000\n",
      "Column: 8, Selected False, Rank: 13.000\n",
      "Column: 9, Selected True, Rank: 1.000\n",
      "Column: 10, Selected False, Rank: 2.000\n",
      "Column: 11, Selected False, Rank: 7.000\n",
      "Column: 12, Selected True, Rank: 1.000\n",
      "Column: 13, Selected False, Rank: 10.000\n",
      "Column: 14, Selected False, Rank: 15.000\n",
      "Column: 15, Selected False, Rank: 16.000\n",
      "Column: 16, Selected False, Rank: 8.000\n",
      "Column: 17, Selected False, Rank: 9.000\n",
      "Column: 18, Selected False, Rank: 18.000\n",
      "Column: 19, Selected False, Rank: 21.000\n",
      "Column: 20, Selected False, Rank: 22.000\n",
      "Column: 21, Selected False, Rank: 19.000\n",
      "Column: 22, Selected True, Rank: 1.000\n",
      "Column: 23, Selected False, Rank: 6.000\n",
      "Column: 24, Selected True, Rank: 1.000\n",
      "Column: 25, Selected False, Rank: 20.000\n",
      "Column: 26, Selected True, Rank: 1.000\n",
      "Column: 27, Selected False, Rank: 14.000\n",
      "Column: 28, Selected True, Rank: 1.000\n",
      "Column: 29, Selected True, Rank: 1.000\n",
      "Column: 30, Selected False, Rank: 17.000\n",
      "Column: 31, Selected True, Rank: 1.000\n",
      "Column: 32, Selected True, Rank: 1.000\n",
      "Column: 33, Selected False, Rank: 5.000\n",
      "Column: 34, Selected True, Rank: 1.000\n",
      "Column: 35, Selected True, Rank: 1.000\n",
      "Column: 36, Selected True, Rank: 1.000\n",
      "Column: 37, Selected True, Rank: 1.000\n",
      "Column: 38, Selected True, Rank: 1.000\n",
      "Column: 39, Selected False, Rank: 3.000\n",
      "Column: 40, Selected False, Rank: 12.000\n",
      "(125973, 20) (22544, 20)\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(estimator=DecisionTreeClassifier(), n_features_to_select=20)\n",
    "# fit RFE\n",
    "rfe.fit(X_train, y_train)\n",
    "# summarize all features\n",
    "rfe_X_train = pd.DataFrame()\n",
    "rfe_X_test = pd.DataFrame()\n",
    "for i in range(X_train.shape[1]):\n",
    "    print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support_[i], rfe.ranking_[i]))\n",
    "    col_name_train = train[train.columns[i]]\n",
    "    col_name_test = test[test.columns[i]]\n",
    "    if rfe.support_[i]:\n",
    "        rfe_X_train = pd.concat([rfe_X_train, col_name_train], axis = 1)\n",
    "        rfe_X_test = pd.concat([rfe_X_test, col_name_test], axis = 1)\n",
    "      \n",
    "print (rfe_X_train.shape, rfe_X_test.shape)\n",
    "#print(col_name_train)"
   ]
  },
  {
   "source": [
    "# PSO-ELM\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25, 630) [[-1.71438955  4.24321173 -0.70221343 -3.38114733  1.59024107  1.37902011\n  -0.17101453 -1.31904073  1.78932785  4.05071167 -3.20453577  4.82866924\n   3.30822788 -0.30779593 -2.20016388  2.99112718  1.00649762 -2.64776329\n  -2.45683355 -3.87979988 -2.65437441  1.03808591 -3.7470437  -2.84659348\n  -0.36501994 -3.4172665   0.01961334 -3.57550571  2.31151301  1.1958929 ]\n [-0.36868486 -4.70372524  1.29238803 -3.4145357   0.24143257 -3.73787257\n   4.64537514  3.16299401  4.43435579 -3.38297696 -3.82837246 -1.77439351\n  -4.32831218 -3.12667858  1.13969446 -3.95014242 -4.04443614 -1.35450605\n  -2.09652334 -3.92237037 -4.96059255 -3.83152028 -2.05475114 -0.1234468\n   1.80269141  1.71945067 -1.38629427  3.73092922  1.96903479  0.718721  ]\n [-1.46430064 -3.10252749 -1.78835004 -3.88179153 -1.0034729   1.55528406\n  -4.73103983  1.27884977  2.61724618 -4.90308326  0.53690747  1.99385141\n   0.67655108 -4.09136973  2.81585123 -4.98455147  3.86167359  2.76694381\n   2.74902404  4.29560492 -3.50636782  3.01388959 -3.73022641  4.67488907\n  -4.94256565  4.85602393 -3.43572105  3.97608306  4.47490062 -3.46772646]\n [-2.77683735 -1.81979578  4.45915759 -2.07026778 -4.81285307  2.68755602\n   3.79516257  0.15036297  0.87666823  0.66193352 -4.17949468  0.4479876\n  -4.8088005  -2.06688686 -1.41244584  0.65948221  2.00499746  2.35185612\n   4.719773   -3.99692902  0.82995213 -0.51813166  4.1036521  -1.09979564\n   0.04928746  3.48336626  4.91091326 -4.22049944 -0.34047494 -1.58890956]\n [-2.99283258 -3.03869416 -4.08123814 -2.45524765 -3.65246072  1.48079939\n  -3.43005465  0.47289504  3.12082035  4.63190568 -0.36104474  2.42553166\n  -4.53151246 -3.84514998  4.83754049 -3.09171706 -2.53731459  3.77836585\n   4.28576605 -0.19954058  2.12398752 -4.75632334  2.96422768 -1.76594934\n   2.09775872  4.21615924 -1.00167771 -3.80248746  3.15407793 -4.19772319]\n [-4.16137413  4.3144498   0.48838071  4.77695416  1.21514352  4.10533114\n   1.9017626  -3.52659163 -4.18832811  1.66263001 -1.66574103 -2.87006834\n  -4.90065043 -4.74694151 -0.46329178 -2.15246208  1.24789133  2.8687586\n   1.21504734 -1.7503141   4.72549206 -4.47995699 -4.15501406  3.31033454\n  -4.70760483 -0.85842374  1.95186844  2.07587744 -3.67614444  0.71899118]\n [ 0.96854746  1.26436545  3.4706777   1.50462352 -2.04557079 -3.89863455\n   2.71694492 -4.77160073  2.6705345  -0.5703587  -4.03286657  3.90504764\n  -4.05504851 -1.39850897  4.31896505  1.35720201  2.89170553 -0.07004728\n   3.00654764  0.85434069 -0.75505502  3.99362484 -4.82982458  4.91840803\n  -2.38984974 -0.11515839  4.78351094 -0.67751405 -3.64957476 -2.84283057]\n [-2.34159142 -0.43270616 -3.0362685   4.665451    0.70311645  4.66908558\n  -4.79274227  0.77054503  1.4355345  -1.06370749 -4.64505757 -2.07960977\n  -2.66316335  2.95527105  0.59727459  0.21065573 -4.82153826  3.38046494\n   1.72379408 -3.16258189  3.74475646  1.08091668  2.08750499  3.81438874\n  -4.97001143 -1.78783701 -2.94136175  1.62384392  4.82023138 -2.32150454]\n [-2.31973438 -1.35303469  3.29633717  1.97792472 -2.21151823 -2.37299228\n  -1.15947388  3.77702257  1.52744411 -4.66673049  2.93628502 -3.08413134\n  -1.093766    0.73175939  4.71051557 -1.33188749  1.68999784 -2.58890836\n   3.2264372  -4.42165339  1.06417857 -4.48395145 -4.37334313 -1.02402869\n   4.8744935  -3.53566756 -1.37733199 -4.01293374 -1.95031098 -4.59760682]\n [-2.24079563  1.32264093  1.53883598 -0.70469656  3.52367403  0.2963469\n   1.43518013  3.29370921  4.42075149  1.70596672  4.39797097  1.0739402\n  -4.13686216  3.69065562  0.06018865  2.02780946 -4.96094348  0.2781779\n   2.58067456 -1.96701868 -0.74072793 -3.14521889  4.56835351 -0.00619079\n   4.30869364 -1.57657159 -0.5977211   2.92000624 -0.4976822   4.54798339]\n [ 2.34473526 -1.69524028  1.6658961   3.13330629  4.15706755  3.38492609\n   0.63604434  2.83201112 -0.7897941   1.62665606 -2.58554502  2.31471496\n   4.7707517  -3.42605366  4.95817118 -1.04070435  1.53177305 -3.78108654\n   1.1388908  -0.39848781  4.01971291 -0.91098396 -0.38349092  0.30951752\n   1.89026515 -4.87284741  2.41150403  0.26838313  2.84970067  4.14264779]\n [-0.29117433 -3.10466563  4.73959153  3.48248111  3.45605791  3.00979522\n   4.0304641  -4.16934974 -4.53471968 -1.61215489 -1.69218976 -2.98040909\n   2.65212357 -2.17868262 -2.65726597  2.88131511 -1.22956203  4.87061716\n  -3.55375931 -0.86402758  0.82191093  0.21968698  2.3343687   3.98531666\n   3.60214516 -3.78991607 -1.89471318  4.22029335 -4.47535981  0.7537156 ]\n [-0.60402833  1.64943044 -0.32193909 -4.02253809 -4.3955503   0.00565333\n  -1.29343825  3.89084956  3.66201778  2.24654776 -3.93479828  1.94668366\n   2.5844783  -0.74689684  0.24399029 -0.54737219 -1.57225735 -3.93555024\n  -1.31919613  4.2198165   0.27346264  2.61330371  0.43533423  4.83237704\n  -1.51837029 -3.77087551 -1.8630314   0.49599661  0.29796155  1.06406879]\n [-1.29696032 -0.47775362 -3.10690522 -1.00047574 -4.83406185  4.71822618\n   0.28659612  3.13241271 -0.41678086 -3.07491453  2.49577962 -1.75572973\n  -0.57119986 -3.23153896  4.38618789 -4.40443862 -3.51733424  0.45713248\n  -0.9709856   1.95624177  4.62141908  2.87131135  1.85830888 -4.04089108\n  -1.50932226 -1.73823996 -2.58961516  2.98194966 -0.37399665  3.30130115]\n [-4.36640717  4.62503203  3.63741301  1.20626621  1.51931712  4.32003524\n   4.30166387 -0.50404093  0.12708303  1.38124794  3.65360696  1.73780076\n  -4.352455   -3.89821207 -4.52666022  4.1362751  -3.04204695 -1.15487365\n  -0.95221086  4.34873581  3.09094472 -2.55980189  3.07690773  2.10229722\n   4.22311277  3.35932462  0.67744167  0.7983615   2.43554167  0.52646481]\n [-2.74458252 -1.5572076  -2.08208697  2.7448002  -1.20617658 -4.36596349\n  -4.33613297 -2.06311213 -3.55358179 -2.20500174 -0.03137578 -0.63636154\n   0.28865428 -1.78642904 -0.58483803  1.91089851 -4.96927818 -2.57978406\n  -2.97136452 -0.27736167 -0.09347902  3.00138047 -1.25064638  3.66313724\n   2.94530594 -1.02997242  3.2504141   2.02281235  1.67246222  2.52272402]\n [-0.85418393 -1.49022357 -0.25807423  0.79238397 -3.31143279  4.33039193\n   2.5981888  -1.18563118  2.2337159  -0.15529895  3.2742093  -0.08279255\n   3.09663925 -2.50144048 -2.64736322  0.62848292 -1.94893415 -1.02181689\n  -0.84279034 -4.66443051  2.69822368  2.72669181 -1.96316335 -2.19660798\n   3.64911402 -0.98486986  0.1944812   0.50889342 -4.86312845  0.38606946]\n [ 1.26060898  0.16274505 -3.39055372 -4.41870419  2.6434186  -0.02073323\n   3.57601485  3.23585719 -3.07791841 -2.72697923 -2.43837116 -2.83268475\n  -4.63590566  1.65592171  1.87876075 -1.78405163  1.18277453  3.69169615\n  -4.51995482 -2.4274428   4.69156461  0.18384152 -0.30376325 -1.00323661\n   4.77051812  2.16796436 -1.9267863   0.774288   -0.27247568  4.5553671 ]\n [ 0.08684967  0.15616854 -4.76824258 -4.81091609 -4.59050368 -1.76387276\n  -0.03551949  1.51811826 -1.63631003 -3.09004912  0.47026485 -2.91762398\n   3.17303779  3.77064187 -3.32780848  2.21210966 -3.13185634  3.3887521\n   1.53183109  2.05429618  0.02369536 -2.76259421  1.16904473 -0.78868963\n  -0.32281014 -2.94744811 -1.88812602 -2.9419263  -3.59103224 -2.0583115 ]\n [ 1.55058446 -3.5939747   1.01648183 -3.23947053 -4.11215993  4.08401856\n   4.16496331  2.20851882 -1.30988959 -4.81479708 -2.4837604   1.18344195\n   0.30122078 -2.31016564  2.65634273 -1.53654641  2.63604342 -2.67455571\n   1.80584285 -2.99025342  0.38287953  2.22426942  1.05108268  1.90514363\n  -2.15514555 -2.87901013 -2.18644665 -1.29287894 -4.99497615  1.38810486]\n [ 1.88771197 -4.7498264   0.36253477  3.18571493  1.59344345  2.93958315\n  -3.03023245 -2.14652647  0.03367547 -2.97343216  0.59596776  4.78947391\n  -3.63783038  3.61051542 -4.65707058 -4.18196404  2.11079739 -1.66519221\n   1.80140166  3.21974565 -1.70910815 -4.01618457  0.04153958 -0.7645809\n  -0.36407824 -4.27162836  3.17741998 -4.5959086   0.86809469 -2.47713863]\n [ 0.30163504  2.45752941  2.84896975 -3.78614005 -0.25872176 -4.18331714\n  -2.51625073  4.11479481 -2.53862222  4.75407325 -2.96357627  4.21162149\n  -4.45865345 -3.06252078 -1.26694715 -4.8151482   2.39258586 -3.16024891\n  -3.48651849  3.92114263 -2.03221935  2.68319738 -1.99834363 -3.92823045\n  -3.82239143  3.26942063  4.8854804   0.32250626  4.23397812  0.27360716]\n [ 1.79149466  1.92765255  0.78351985 -4.52530034 -0.60428651  1.30851824\n  -4.59728043  3.47747895  3.77009703 -4.90864182  1.20674189 -3.71396156\n  -1.31110124  3.61983755 -0.33723159  1.20875311 -3.75870811  0.63788052\n   1.81495643 -4.10923316  1.88217213  2.9830562  -1.6215314  -3.68705428\n   2.40182824 -0.15154515  4.95883725 -3.76277132 -4.63181502 -3.23334808]\n [-4.30367396 -1.61511992 -4.71143385  3.94654553  0.79543712  0.37991874\n  -3.16675123  1.1077425   1.20503325  2.93991779 -2.26588917  0.22282762\n   0.70139154 -0.10743113  0.13222726 -1.87093158 -0.6404769  -3.4025114\n   4.04098541 -0.66564985  0.61084772 -3.17713696 -0.73071438  2.26208686\n   4.69041051  3.03185034 -2.88808365 -0.21294673  1.63711619 -1.52399022]\n [-3.87835529  3.58368014 -4.31301611 -2.09545357 -0.42093482  2.43782398\n  -2.54002531  0.68349645  4.55724494  0.60141625  2.21888607  1.52861217\n  -4.86279026 -3.6868024  -0.20130494  4.58958136 -4.09650985  0.21554825\n   4.4289326  -1.44889882 -4.8071016  -3.89503529 -4.62562645  4.48341622\n  -0.69074825  0.58665804 -3.25267877 -4.62441465  0.93009154 -2.47135055]]\n"
     ]
    }
   ],
   "source": [
    "input_size = rfe_X_train.shape[1]\n",
    "hidden_size = 30\n",
    "\n",
    "\n",
    "weights = np.array([np.random.uniform(-5,5, size=(input_size, hidden_size)) for i in range(25)])\n",
    "bias = np.array([np.random.uniform(-5,5,hidden_size) for i in range(25)])\n",
    "velocity_x = np.array([np.array([0 for j in range((input_size*hidden_size)+hidden_size)]) for i in range(25)])\n",
    "\n",
    "input_weight_x = []\n",
    "\n",
    "for i in range(25):\n",
    "    input_weight_x.append(np.concatenate((weights[i].flatten(),bias[i])))\n",
    "\n",
    "input_weight_x = array(input_weight_x)\n",
    "print(input_weight_x.shape,bias)"
   ]
  },
  {
   "source": [
    "## ELM (Fitness Function)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def hidden_nodes(X,input_weights,bias):\n",
    "    G = np.dot(X, input_weights)\n",
    "    G = G + bias\n",
    "    H = sigmoid(G)\n",
    "    return H\n",
    "\n",
    "def predict(X,input_weights,output_weights,bias):\n",
    "    out = hidden_nodes(X,input_weights,bias)\n",
    "    out = np.dot(out, output_weights)\n",
    "    return out\n",
    "\n",
    "def ELM_fitness(row):\n",
    "    input_weights = row[:(input_size*hidden_size)].reshape(input_size,hidden_size)\n",
    "    bias = row[-hidden_size:]\n",
    "    output_weights = np.dot(pinv2(hidden_nodes(rfe_X_train,input_weights,bias)), y_train)\n",
    "    #pred\n",
    "    prediction = predict(rfe_X_test,input_weights,output_weights,bias)\n",
    "\n",
    "    return mean_squared_error(y_test,prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999, 999] (25, 630)\n"
     ]
    }
   ],
   "source": [
    "p_best, p_best_x = [999 for row in input_weight_x], input_weight_x\n",
    "g_best, g_best_x = 999,[]\n",
    "print(p_best,p_best_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[0.14187905 0.14158088]\n [0.19423788 0.36188961]\n [0.44357998 0.18585577]\n [0.53045679 0.16708379]\n [0.08532058 0.37810872]\n [0.11528206 0.40656828]\n [0.33018683 0.20427899]\n [0.06664516 0.48452822]\n [0.17588886 0.75303205]\n [0.22212796 0.06222223]\n [0.97889795 0.16673115]\n [0.72041394 0.54005196]\n [0.33960854 0.28737111]\n [0.72099115 0.31421369]\n [0.471728   0.18378947]\n [0.4814248  0.06069019]\n [0.28054827 0.25314772]\n [0.5844566  0.24913173]\n [0.93674045 0.54067596]\n [0.0739223  0.08512094]\n [0.15930631 0.66303691]\n [0.49320477 0.2921483 ]\n [0.50346092 0.17925975]\n [0.54767606 0.59170514]\n [0.67763138 0.78493512]\n [0.5494428  0.51676766]\n [0.7409649  0.2017191 ]\n [0.27713128 0.05406928]\n [0.62902519 0.36110205]\n [0.44960733 0.3826797 ]]\n"
     ]
    }
   ],
   "source": [
    "random_numbers = np.array([np.random.uniform(0,1,2) for i in range(30)])\n",
    "print(random_numbers)"
   ]
  },
  {
   "source": [
    "## Velocity Calculation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = 1\n",
    "c2 = 2\n",
    "w = 0.6\n",
    "def calculate_v(old_v,c1,c2,r1,r2,x,p_best_x,g_best_x):\n",
    "  return w*old_v + c1*r1*(p_best_x-x) + c2*r2*(g_best_x-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done with:  0\n",
      "Done with:  1\n",
      "Done with:  2\n",
      "Done with:  3\n",
      "Done with:  4\n",
      "Done with:  5\n",
      "Done with:  6\n",
      "Done with:  7\n",
      "Done with:  8\n",
      "Done with:  9\n",
      "Done with:  10\n",
      "Done with:  11\n",
      "Done with:  12\n",
      "Done with:  13\n",
      "Done with:  14\n",
      "Done with:  15\n",
      "Done with:  16\n",
      "Done with:  17\n",
      "Done with:  18\n",
      "Done with:  19\n",
      "Done with:  20\n",
      "Done with:  21\n",
      "Done with:  22\n",
      "Done with:  23\n",
      "Done with:  24\n",
      "Done with:  25\n",
      "Done with:  26\n",
      "Done with:  27\n",
      "Done with:  28\n",
      "Done with:  29\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(0,30):\n",
    "    input_weight_x = input_weight_x + velocity_x\n",
    "    current_x = [ELM_fitness(row) for row in input_weight_x]\n",
    "    for i,f_val in enumerate(current_x):\n",
    "        if p_best[i] > f_val:\n",
    "            p_best[i] = f_val\n",
    "            p_best_x[i] = input_weight_x[i]\n",
    "        if p_best[i] < g_best:\n",
    "            g_best = p_best[i]\n",
    "            g_best_x = p_best_x[i]\n",
    "        v = []\n",
    "    print(\"Done with: \",iteration)\n",
    "    for i, particle in enumerate(input_weight_x):\n",
    "        v.append(calculate_v(velocity_x[i],c1,c2,random_numbers[iteration][0], random_numbers[iteration][1],particle,p_best_x[i],g_best_x))\n",
    "    velocity_x = np.array(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "42.072745576895805\n6.486350713374648\n"
     ]
    }
   ],
   "source": [
    "#print(g_best_x.shape,g_best_x)\n",
    "print(g_best)\n",
    "print(math.sqrt(g_best))"
   ]
  },
  {
   "source": [
    "# Best Input-Weight And Bias"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(20,)\n",
      "<ipython-input-117-13c3d2f2b0f1>:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x))\n",
    "\n",
    "def hidden_nodes(X):\n",
    "    G = np.dot(X, input_weights)\n",
    "    G = G + bias\n",
    "    H = sigmoid(G)\n",
    "    return H\n",
    "\n",
    "input_weights = g_best_x[:400].reshape(input_size,hidden_size)\n",
    "bias = g_best_x[-hidden_size:]\n",
    "output_weights = np.dot(pinv2(hidden_nodes(rfe_X_train)), y_train)\n",
    "print(output_weights.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-117-13c3d2f2b0f1>:2: RuntimeWarning: overflow encountered in exp\n  return 1.0 / (1.0 + np.exp(-x))\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "44.19176599137174"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "def predict(X):\n",
    "    out = hidden_nodes(X)\n",
    "    out = np.dot(out, output_weights)\n",
    "    return out\n",
    "\n",
    "prediction = predict(rfe_X_test)\n",
    "mean_squared_error(y_test,prediction)"
   ]
  },
  {
   "source": [
    "## Experimental Results\n",
    "* Hidden-Neurons = 10\n",
    "    * ELM(MSE = 48.14757009978859,RMSE = 6.9388450119446095)\n",
    "\n",
    "    * PSO-ELM(MSE=44.802622846415446,RMSE=6.6934761407220575)\n",
    "\n",
    "* Hidden-Neurons = 20\n",
    "    * ELM(MSE = 47.31095358876977, RMSE = 6.878295834635915)\n",
    "    * PSO-ELM(MSE=43.867156139935254,RMSE=6.62322852843953)\n",
    "    \n",
    "* Hidden-Neurons = 30\n",
    "    * ELM(MSE = 46.12265073429617,RMSE=6.791365896069522)\n",
    "    \n",
    "    * PSO-ELM(MSE=42.39817268089611,RMSE=6.511387922777763)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## PSO-ELM Results\n",
    "    * 10 - Iterations (MSE=\"42.39817268089611\", RMSE=\"6.511387922777763\") \n",
    "    * 20 - Iterations (MSE=\"42.09405068660949\", RMSE=\"6.4879928087667835\")\n",
    "    * 30 - Iterations (MSE=\"42.072745576895805\", RMSE=\"6.486350713374648\")"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}